âš–ï¸ LawGpt â€“ AI-Powered Legal Awareness Assistant

LawGpt is a full-stack AI-powered legal assistant that uses Retrieval-Augmented Generation (RAG) to provide accurate, constitution-grounded legal responses.

It consists of:

ğŸ§  Django + DRF Backend API

ğŸ¨ Streamlit Frontend

ğŸ“š FAISS Vector Database (for semantic search)

âš¡ Groq LLM API (for fast inference)

ğŸ—„ PostgreSQL caching (to reduce repeated LLM calls & API costs)

ğŸ— Architecture Overview

User asks question in Streamlit UI

Request sent to Django Backend

FAISS retrieves relevant constitutional context

PostgreSQL cache checked for existing response

If not cached â†’ Groq LLM generates answer

Response stored in DB for future reuse

Answer returned to Streamlit UI

ğŸš€ Local Setup Guide
1ï¸âƒ£ Clone Repository
git clone https://github.com/your-username/LawGpt.git
cd LawGpt

ğŸ”‘ Backend Setup (Django)
2ï¸âƒ£ Create Virtual Environment
python -m venv venv


Activate:

Windows

venv\Scripts\activate


Mac/Linux

source venv/bin/activate

3ï¸âƒ£ Install Backend Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Add Groq API Key

Create a .env file inside backend root:

backend/.env


Add:

GROQ_API_KEY=your_groq_api_key_here


Get your key from:
ğŸ‘‰ https://console.groq.com/keys

Load Environment Variables in settings.py
import os
from dotenv import load_dotenv

load_dotenv()

GROQ_API_KEY = os.getenv("GROQ_API_KEY")

5ï¸âƒ£ Configure PostgreSQL

Update settings.py:

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': 'lawgpt',
        'USER': 'postgres',
        'PASSWORD': 'yourpassword',
        'HOST': 'localhost',
        'PORT': '5432',
    }
}


Run migrations:

python manage.py makemigrations
python manage.py migrate

6ï¸âƒ£ Run Backend Server
python manage.py runserver


Backend runs at:

http://127.0.0.1:8000/

ğŸ¨ Frontend Setup (Streamlit)
7ï¸âƒ£ Install Streamlit (if not included)
pip install streamlit requests

8ï¸âƒ£ Navigate to Frontend Folder
cd frontend

9ï¸âƒ£ Run Streamlit App
streamlit run app.py


Streamlit will run at:

http://localhost:8501

ğŸ“ Project Structure
LawGpt/
â”‚
â”œâ”€â”€ backend/              # Django Backend
â”‚   â”œâ”€â”€ lawgpt/
â”‚   â”œâ”€â”€ manage.py
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ frontend/             # Streamlit UI
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ”¥ Key Features

âœ… RAG-based constitutional retrieval
âœ… Groq ultra-fast inference
âœ… PostgreSQL response caching (reduces LLM API calls)
âœ… Streamlit interactive chat interface
âœ… Tool integration for legal blogs & articles

ğŸ›  Tech Stack

Backend:

Python

Django

Django REST Framework

FAISS

LangChain

Groq API

PostgreSQL

Frontend:

Streamlit

Requests

ğŸ§  Why PostgreSQL Caching?

Instead of calling the LLM repeatedly for similar questions:

Query is first checked in PostgreSQL

If found â†’ return cached answer instantly

If not â†’ call Groq LLM

Store result in DB

This:

âš¡ Improves speed

ğŸ’° Reduces API cost
